{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vggTrain.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "CZmykcEyAyxf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "code"
      },
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.layers import Flatten, Dense,Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.applications import VGG16\n",
        "\n",
        "train_data_dir = 'dataNew/training'\n",
        "\n",
        "validation_data_dir = 'dataNew/validation'\n",
        "\n",
        "train_samples = 6512\n",
        "\n",
        "validation_samples = 1201\n",
        "\n",
        "epoch = 10\n",
        "\n",
        "img_width, img_height = 100, 100\n",
        "\n",
        "# ** Model Begins **\n",
        "conv_base = VGG16(weights='imagenet',include_top=False,input_shape=(100, 100, 3))\n",
        "\n",
        "conv_base.trainable = True\n",
        "\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'block5_conv1':\n",
        "        layer.trainable = True\n",
        "    if layer.name == 'block4_conv1':\n",
        "        layer.trainable = True    \n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "conv_base.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fkvfy3hSA0E3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "model = Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "\n",
        "model.summary()\n",
        "# ** Model Ends **\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "!pip install -U -q pyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "fid = drive.ListFile({'q':\"title='dataNew.zip'\"}).GetList()[0]['id']\n",
        "f = drive.CreateFile({'id': fid})\n",
        "f.GetContentFile('dataNew.zip')\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "files.os.listdir()\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"dataNew.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "    \n",
        "files.os.listdir()    \n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "        rescale=1./255)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        #color_mode = 'grayscale',\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        #color_mode = 'grayscale',\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "history = model.fit_generator(\n",
        "        train_generator,\n",
        "        samples_per_epoch=train_samples,\n",
        "        nb_epoch=epoch,\n",
        "        validation_data=validation_generator,\n",
        "        nb_val_samples=validation_samples)\n",
        "        \n",
        "\n",
        "model.save_weights('vggweights1000.h5')\n",
        "model.save('savedvgg1000l.h5')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        'dataNew/testing',\n",
        "        target_size=(100, 100),\n",
        "        batch_size=1,\n",
        "        class_mode = None,  # only data, no labels\n",
        "        shuffle = False)  # keep data in same order as labels\n",
        "\n",
        "# test_loss,test_acc = model.evaluate_generator(test_generator,steps = 1)\n",
        "# print('test accuracy :',test_acc)\n",
        "# print('test loss :',test_loss)\n",
        "probabilities = model.predict_generator(test_generator, 600)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "y_true = np.array([0] * 100 + [1] * 100 + [2] * 100 + [3] * 100 + [4] *100 + [5] *100 )\n",
        "#y_pred = probabilities > 0.5\n",
        "print(probabilities)\n",
        "y_pred = np.asarray(probabilities)\n",
        "y_pred = np.argmax(probabilities,axis=1)\n",
        "\n",
        "print(y_pred)\n",
        "\n",
        "print(y_true)\n",
        "\n",
        "#print(np.shape(probabilities))\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "print(accuracy_score(y_true, y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BjB6ctlJBIgC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "probabilities = model.predict_generator(test_generator, 600)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "y_true = np.array([0] * 100 + [1] * 100 + [2] * 100 + [3] * 100 + [4] *100 + [5] *100 )\n",
        "#y_pred = probabilities > 0.5\n",
        "print(probabilities)\n",
        "y_pred = np.asarray(probabilities)\n",
        "y_pred = np.argmax(probabilities,axis=1)\n",
        "\n",
        "print(y_pred)\n",
        "\n",
        "print(y_true)\n",
        "\n",
        "#print(np.shape(probabilities))\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "print(accuracy_score(y_true, y_pred))\n",
        "\n",
        "\n",
        "# list all data in history\n",
        "\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3_dg6yJD1kVp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "files.os.listdir()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ey6QucCL16cE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "img = cv2.imread('download (1).jpeg')\n",
        "img = cv2.resize(img, (img_width, img_height))\n",
        "img = np.array(img)\n",
        "img = img.reshape(1,100,100,3)\n",
        "prediction = model.predict(img)[0]\n",
        "print(prediction)\n",
        "bestclass = ''\n",
        "bestconf = -1\n",
        "best = ['korean','indian','usa','indonesia','philippines','kenya']\n",
        "for n in [0,1,2,3,4,5]:\n",
        "\tif (prediction[n] > bestconf):\n",
        "\t\tbestclass = n\n",
        "\t\tbestconf = prediction[n]\n",
        "print ('This image is a ' + best[bestclass])\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}